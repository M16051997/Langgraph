{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a937eeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f02b9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Whay is hydrogen is flamable?',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://www.reddit.com/r/explainlikeimfive/comments/118lq04/eli5_what_makes_some_elements_flammable_while/',\n",
       "   'title': \"What makes some elements flammable while others aren't? Why is ...\",\n",
       "   'content': 'Hydrogen is very flammable because its molecules contain only two atoms, which makes it very reactive and able to combine with oxygen to produce',\n",
       "   'score': 0.81347597,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.aiche.org/sites/default/files/docs/pages/the_elemental_-_hydrogen_flammability.pdf',\n",
       "   'title': '[PDF] Hydrogen Flammability - AIChE',\n",
       "   'content': \"View in Web Browser Hydrogen Flammability All fuels have a unique flammable range, which is the minimum and maximum concentration in air necessary for combustion to occur. Hydrogen's flammability range (between 4% and 75% in air) is extensive compared to other fuels, as shown below. Along with its wide flammability range, one safety concern with hydrogen is that it takes very little energy to ignite. Under the optimal combustion condition (a 29% hydrogen-to-air volume ratio), the energy required to initiate hydrogen combustion is much lower than that required for other common fuels (e.g., a small spark will ignite it), as shown. But at low concentrations of hydrogen in air, the energy required to initiate combustion is like that of other fuels.\",\n",
       "   'score': 0.7975099,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://www.inchem.org/documents/icsc/icsc/eics0001.htm',\n",
       "   'title': 'ICSC 0001 - HYDROGEN - INCHEM',\n",
       "   'content': 'Hydrogen is extremely flammable, forming explosive gas/air mixtures. It can cause frostbite, and heating may cause violent combustion or explosion. It is',\n",
       "   'score': 0.79522943,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://cameochemicals.noaa.gov/chemical/8729',\n",
       "   'title': 'HYDROGEN | CAMEO Chemicals | NOAA',\n",
       "   'content': 'Hydrogen is a colorless, odorless, easily ignited gas. It is flammable, burns with a pale blue flame, and is lighter than air. It is not toxic but can cause',\n",
       "   'score': 0.77548623,\n",
       "   'raw_content': None},\n",
       "  {'url': 'http://www.osha.gov/green-jobs/hydrogen/fire-explosion',\n",
       "   'title': 'Green Job Hazards - Hydrogen Fuel Cells: Fire and Explosion - OSHA',\n",
       "   'content': 'Hydrogen used in the fuel cells is a very flammable gas and can cause fires and explosions if it is not handled properly. Hydrogen fires are invisible and if a worker believes that there is a hydrogen leak, it should always be presumed that a flame is present.',\n",
       "   'score': 0.7366474,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 0.97,\n",
       " 'request_id': 'f0bc271d-9cca-4135-8f29-384ac20d9241'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "tool = TavilySearch(api_key=TAVILY_API_KEY)\n",
    "tools = [tool]\n",
    "tool.invoke(\"Whay is hydrogen is flamable?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f88490",
   "metadata": {},
   "source": [
    "### Agent with tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3de87cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information I found, here's a summary of the discussions between Prime Minister Modi and President Putin during their recent SCO meeting:\n",
      "\n",
      "*   **Bilateral Cooperation:** They discussed ways to deepen cooperation in various sectors, including trade, fertilizers, space, security, and culture.\n",
      "*   **Regional and Global Developments:** They exchanged views on regional and global developments, including the peaceful resolution of the conflict in Ukraine. Modi welcomed initiatives aimed at halting the conflict and called for constructive steps to establish peace.\n",
      "*   **Strategic Partnership:** They reaffirmed their commitment to strengthening the \"special and privileged strategic partnership\" between India and Russia, emphasizing its importance for regional and global stability.\n",
      "*   **Ukraine Conflict:** Modi expressed hope that both sides would move forward to end the war soon.\n",
      "*   **Upcoming Summit:** Modi mentioned he was looking forward to receiving Putin in India for the 23rd India-Russia annual summit later in the year.\n",
      "\n",
      "Additionally, it's worth noting that Putin waited for Modi to travel together to the venue of their bilateral meeting and they had insightful conversations in the car.\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Define the Agent State\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Create a proper tool function\n",
    "@tool \n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search the web for current information and recent events.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query string\n",
    "        \n",
    "    Returns:\n",
    "        Search results as a string\n",
    "    \"\"\"\n",
    "    search = TavilySearchResults(api_key=TAVILY_API_KEY, max_results=30)\n",
    "    results = search.invoke(query)\n",
    "    \n",
    "    # Format the results nicely\n",
    "    formatted_results = []\n",
    "    for result in results:\n",
    "        title = result.get('title', 'No title')\n",
    "        content = result.get('content', 'No content')\n",
    "        url = result.get('url', 'No URL')\n",
    "        formatted_results.append(f\"Title: {title}\\nContent: {content}\\nURL: {url}\\n\")\n",
    "    \n",
    "    return \"\\n---\\n\".join(formatted_results)\n",
    "\n",
    "# Define tools list\n",
    "tools = [web_search]\n",
    "\n",
    "# Create tool node\n",
    "from langgraph.prebuilt import ToolNode\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Create Agent function\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def chatbot(state: AgentState):\n",
    "    '''Agent node that decides what to do'''\n",
    "    \n",
    "    # Create prompt that guides the agent\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a helpful assistant with extensive knowledge about science, history, and general topics.\n",
    "\n",
    "        ONLY use the web_search tool when users ask about:\n",
    "        - Current events, recent news, or anything happening \"now\" or \"recently\"\n",
    "        - Real-time information (stock prices, weather, sports scores)\n",
    "        - Recent meetings, conferences, or political events\n",
    "        - Latest developments or updates (within the last few months)\n",
    "        - Specific dates or events after 2024\n",
    "        \n",
    "        DO NOT use web_search for:\n",
    "        - Basic scientific facts (like properties of elements, atoms, chemistry)\n",
    "        - Historical information\n",
    "        - General knowledge questions\n",
    "        - Mathematical or logical problems\n",
    "        - Definitions or explanations of concepts\n",
    "        \n",
    "        For these topics, use your built-in knowledge to provide accurate answers.\n",
    "        Be conversational and helpful!\"\"\"),\n",
    "        (\"placeholder\", \"{messages}\")\n",
    "    ])\n",
    "\n",
    "    # Bind tools to the LLM\n",
    "    chain = prompt | llm.bind_tools(tools)\n",
    "    \n",
    "    # Invoke with the full message history\n",
    "    response = chain.invoke({\"messages\": state[\"messages\"]})\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Decides what to do next\"\"\"\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the AI wants to use a tool, go to tools\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise we're done\n",
    "    return END\n",
    "\n",
    "# Build the graph\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set entry point\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Add conditional edges\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\", \n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After using tools, go back to chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# Example interaction\n",
    "if __name__ == \"__main__\":\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"What discussions went on between Prime Minister Modi and putin during there recent SCO meeting?\"}]\n",
    "    })\n",
    "    \n",
    "    # Print the final response\n",
    "    print(response[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     response = graph.invoke({\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": \"How many electorns inside Hydrogen atom? Why hydrgen is explosive?\"}]\n",
    "#     })\n",
    "    \n",
    "#     # Print the final response\n",
    "#     print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "338f1f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A neutral hydrogen atom has **one** electron.\n",
      "\n",
      "Hydrogen is explosive due to these reasons:\n",
      "\n",
      "*   **Flammability:** Hydrogen gas (H2) is highly flammable and requires very little energy to ignite when mixed with air.\n",
      "*   **Wide flammability range:** Hydrogen can form explosive mixtures with air in a wide range of concentrations (4-74%).\n",
      "*   **Reactivity with oxygen:** Hydrogen reacts vigorously with oxygen, releasing a large amount of energy in the process, which causes explosions.\n"
     ]
    }
   ],
   "source": [
    "# Example interaction\n",
    "if __name__ == \"__main__\":\n",
    "    response = graph.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"How many electorns inside Hydrogen atom? Why hydrgen is explosive?\"}]\n",
    "    })\n",
    "    \n",
    "    # Print the final response\n",
    "    print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee9d2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b144a8",
   "metadata": {},
   "source": [
    "## Adding memory to the agent\n",
    "\n",
    "Right now, our agent:\n",
    "\n",
    "Handles one-shot queries.\n",
    "\n",
    "Keeps messages inside a single run, but forgets after execution.\n",
    "\n",
    "Adding memory means:\n",
    "\n",
    "The graph can remember past conversations across turns.\n",
    "\n",
    "User doesn’t have to repeat context every time.\n",
    "\n",
    "The agent feels more “chat-like” instead of “Q&A only.”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b8e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1. The Problem Without Memory\n",
    "\n",
    "Example with your current code:\n",
    "\n",
    "User: Who won the 2022 FIFA World Cup?\n",
    "Agent: Argentina won the 2022 FIFA World Cup.\n",
    "User: Where was it held?\n",
    "Agent: Sorry, I don’t know what you’re referring to.\n",
    "\n",
    "👉 The agent forgets that the previous topic was the World Cup.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"2. The Idea of Memory\n",
    "\n",
    "We need to persist conversation state across multiple invocations.\n",
    "\n",
    "LangGraph lets us:\n",
    "\n",
    "Store checkpoints → snapshots of agent state.\n",
    "\n",
    "Use a memory backend → like SQLite, Postgres, Redis, or even in-memory dicts.\n",
    "\n",
    "Reload conversation history automatically.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b9473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AgentStateOnly use InMemorySaver for debugging or testing purposes.\\nFor production use cases we recommend installing langgraph-checkpoint-postgres and using PostgresSaver / AsyncPostgresSaver.\\nIf you are using the LangGraph Platform, no checkpointer needs to be specified. The correct managed checkpointer will be used automatically.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add Checkpoint Saver\n",
    "\n",
    "## LangGraph provides a MemorySaver:\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver, InMemorySaver\n",
    "memory = MemorySaver()\n",
    "'''AgentStateOnly use InMemorySaver for debugging or testing purposes.\n",
    "For production use cases we recommend installing langgraph-checkpoint-postgres and using PostgresSaver / AsyncPostgresSaver.\n",
    "If you are using the LangGraph Platform, no checkpointer needs to be specified. The correct managed checkpointer will be used automatically.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeef093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Graph to Use Memory\n",
    "\n",
    "# When compiling your graph, attach the memory:\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Now the graph will automatically save state at every step and reload it for the next user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c1b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interact with your chatbot¶\n",
    "# Now you can interact with your bot!\n",
    "\n",
    "# Pick a thread to use as the key for this conversation.\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9f0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Flow with Memory\n",
    "\n",
    "\"\"\"\n",
    "User: Who won the 2022 FIFA World Cup?\n",
    "Agent: Argentina won the 2022 FIFA World Cup.\n",
    "User: Where was it held?\n",
    "Agent: It was held in Qatar.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2647cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Define the Agent State\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", api_key=GOOGLE_API_KEY)\n",
    "memory = InMemorySaver()\n",
    "# Create a proper tool function\n",
    "@tool \n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search the web for current information and recent events.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query string\n",
    "        \n",
    "    Returns:\n",
    "        Search results as a string\n",
    "    \"\"\"\n",
    "    search = TavilySearchResults(api_key=TAVILY_API_KEY, max_results=30)\n",
    "    results = search.invoke(query)\n",
    "    \n",
    "    # Format the results nicely\n",
    "    formatted_results = []\n",
    "    for result in results:\n",
    "        title = result.get('title', 'No title')\n",
    "        content = result.get('content', 'No content')\n",
    "        url = result.get('url', 'No URL')\n",
    "        formatted_results.append(f\"Title: {title}\\nContent: {content}\\nURL: {url}\\n\")\n",
    "    \n",
    "    return \"\\n---\\n\".join(formatted_results)\n",
    "\n",
    "# Define tools list\n",
    "tools = [web_search]\n",
    "\n",
    "# Create tool node\n",
    "from langgraph.prebuilt import ToolNode\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Create Agent function\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def chatbot(state: AgentState):\n",
    "    '''Agent node that decides what to do'''\n",
    "    \n",
    "    # Create prompt that guides the agent\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"\"\"You are a helpful assistant with extensive knowledge about science, history, and general topics.\n",
    "\n",
    "        ONLY use the web_search tool when users ask about:\n",
    "        - Current events, recent news, or anything happening \"now\" or \"recently\"\n",
    "        - Real-time information (stock prices, weather, sports scores)\n",
    "        - Recent meetings, conferences, or political events\n",
    "        - Latest developments or updates (within the last few months)\n",
    "        - Specific dates or events after 2024\n",
    "        \n",
    "        DO NOT use web_search for:\n",
    "        - Basic scientific facts (like properties of elements, atoms, chemistry)\n",
    "        - Historical information\n",
    "        - General knowledge questions\n",
    "        - Mathematical or logical problems\n",
    "        - Definitions or explanations of concepts\n",
    "        \n",
    "        For these topics, use your built-in knowledge to provide accurate answers.\n",
    "        Be conversational and helpful!\"\"\"),\n",
    "        (\"placeholder\", \"{messages}\")\n",
    "    ])\n",
    "\n",
    "    # Bind tools to the LLM\n",
    "    chain = prompt | llm.bind_tools(tools)\n",
    "    \n",
    "    # Invoke with the full message history\n",
    "    response = chain.invoke({\"messages\": state[\"messages\"]})\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"Decides what to do next\"\"\"\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If the AI wants to use a tool, go to tools\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise we're done\n",
    "    return END\n",
    "\n",
    "# Build the graph\n",
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set entry point\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Add conditional edges\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\", \n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After using tools, go back to chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "# Example interaction\n",
    "# if __name__ == \"__main__\":\n",
    "#     response = graph.invoke({\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": \"What discussions went on between Prime Minister Modi and putin during there recent SCO meeting?\"}]\n",
    "#     })\n",
    "    \n",
    "#     # Print the final response\n",
    "#     print(response[\"messages\"][-1].content)\n",
    "\n",
    "# thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     response = graph.invoke({\n",
    "#         \"messages\": [{\"role\": \"user\", \"content\": \"How many electorns inside Hydrogen atom? Why hydrgen is explosive?\"}]\n",
    "#     }, \n",
    "#     config= thread\n",
    "#     )\n",
    "    \n",
    "#     # Print the final response\n",
    "#     print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What is a Thread ID?\n",
    "\n",
    "A thread = one conversation (like a chat session between a user and the agent).\n",
    "\n",
    "The thread_id is just a unique identifier (string) that LangGraph uses to know which conversation memory to load and update.\n",
    "\n",
    "👉 Think of it as the conversation ID in WhatsApp — every chat with a friend has a separate ID, so your chats don’t mix.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "228d1afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heterocyclic compounds are organic compounds that contain a ring structure containing at least one atom other than carbon (C) as a member of the ring. These non-carbon atoms are called heteroatoms, and the most common ones are nitrogen (N), oxygen (O), and sulfur (S). Heterocyclic compounds can be simple aromatic rings or non-aromatic rings.\n",
      "\n",
      "Here's a more detailed breakdown:\n",
      "\n",
      "*   **Ring Structure:** The defining feature is the presence of a ring. This ring can be of various sizes (3-membered, 4-membered, 5-membered, 6-membered, etc.) and can be monocyclic (a single ring) or polycyclic (multiple rings fused together).\n",
      "\n",
      "*   **Heteroatoms:** The presence of one or more heteroatoms (N, O, S, and less commonly other elements like phosphorus or boron) within the ring is crucial. These heteroatoms replace carbon atoms in the ring structure.\n",
      "\n",
      "*   **Aromatic vs. Non-aromatic:** Heterocyclic compounds can be aromatic (exhibiting special stability due to a delocalized pi electron system, like benzene) or non-aromatic (lacking this special stability). Aromatic heterocycles are particularly important due to their stability and prevalence.\n",
      "\n",
      "*   **Examples:**\n",
      "    *   **Pyrrole, Furan, and Thiophene:** These are 5-membered aromatic heterocycles containing nitrogen, oxygen, and sulfur, respectively.\n",
      "    *   **Pyridine:** A 6-membered aromatic heterocycle containing one nitrogen atom.\n",
      "    *   **Imidazole and Thiazole:** 5-membered heterocycles with two heteroatoms.\n",
      "    *   **Piperidine and Tetrahydrofuran (THF):** Non-aromatic heterocycles.\n",
      "\n",
      "*   **Importance:** Heterocyclic compounds are incredibly important in many areas:\n",
      "    *   **Biochemistry:** They are fundamental building blocks of essential biomolecules like DNA (purines and pyrimidines), RNA, vitamins (e.g., riboflavin, thiamine), and amino acids (e.g., proline, histidine, tryptophan).\n",
      "    *   **Pharmaceuticals:** A large percentage of drugs contain heterocyclic rings. Their structures allow for a wide range of interactions with biological targets.\n",
      "    *   **Agrochemicals:** Many pesticides, herbicides, and fungicides contain heterocyclic rings.\n",
      "    *   **Materials Science:** They are used in dyes, polymers, and other materials.\n",
      "\n",
      "*   **Nomenclature:** Naming heterocyclic compounds can be complex, with both systematic and common names in use. The names often reflect the heteroatoms present and the ring size.\n",
      "\n",
      "In summary, heterocyclic compounds are a vast and important class of organic molecules that play a vital role in many aspects of chemistry, biology, and materials science.\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "response1  = graph.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"please provide me details about the heterocyclic compounds?\"}]\n",
    "    }, \n",
    "    config= thread\n",
    "    )\n",
    "    \n",
    "    # Print the final response1 \n",
    "print(response1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74423419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While many heterocyclic compounds are stable and essential for life, some can be part of explosive materials or used as precursors in their synthesis. The presence of a heterocyclic ring alone doesn't automatically make a compound explosive. Explosivity depends on the overall molecular structure and the presence of specific functional groups that can lead to rapid, exothermic decomposition.\n",
      "\n",
      "Here's a more nuanced explanation:\n",
      "\n",
      "*   **Nitro Groups (-NO2):** The most common way to make a heterocyclic compound explosive is to introduce nitro groups (-NO2) onto the ring. Nitro groups are highly energetic and can cause rapid decomposition. Examples include:\n",
      "    *   **Nitropyrazoles:** These can be explosive, with the degree of explosivity depending on the number and position of the nitro groups.\n",
      "    *   **Nitroimidazoles:** Similar to nitropyrazoles, these can also be explosive.\n",
      "    *   **Nitrofurans:** Some nitrofurans are known to be explosive.\n",
      "\n",
      "*   **Azides (-N3):** Attaching azide groups to a heterocyclic ring can also create explosive compounds. Azides are unstable and prone to decomposition, releasing nitrogen gas.\n",
      "\n",
      "*   **Other Energetic Groups:** Other energetic functional groups, such as nitrate esters or perchlorates, can also be attached to heterocyclic rings to create explosives.\n",
      "\n",
      "*   **Bridged Heterocyclic Systems:** Some complex, bridged heterocyclic systems with strained ring structures can also be explosive due to the high energy stored in the strained bonds.\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "*   **Stability:** Not all nitro- or azido-substituted heterocycles are necessarily highly explosive. The overall stability of the molecule depends on the specific structure and the presence of other functional groups.\n",
      "*   **Sensitivity:** Explosives vary in their sensitivity to initiation (e.g., impact, friction, heat). Some heterocyclic explosives may be relatively insensitive, while others are highly sensitive.\n",
      "*   **Context:** It's important to remember that the potential for a compound to be explosive is a complex property, and it's not solely determined by the presence of a heterocyclic ring. The entire molecular structure must be considered.\n",
      "\n",
      "**In summary, while heterocyclic compounds themselves aren't inherently explosive, they can become explosive when combined with energetic functional groups like nitro groups or azides. The specific structure and properties of the resulting molecule determine its explosive potential.**\n"
     ]
    }
   ],
   "source": [
    "response2  = graph.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"is there any explosives in these compounds?\"}]\n",
    "    }, \n",
    "    config= thread\n",
    "    )\n",
    "    \n",
    "    # Print the final response1 \n",
    "print(response2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f14359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can definitely incorporate phosphorus-containing chemicals into heterocyclic rings. Phosphorus heterocycles are a well-established area of chemistry. The way you add phosphorus and the resulting structure depends on the specific phosphorus compound and the desired properties. Here are some general ways phosphorus can be incorporated:\n",
      "\n",
      "*   **Direct Incorporation into the Ring:** Phosphorus can directly replace a carbon or other heteroatom in the ring structure itself, forming a phosphorus-containing heterocycle. For example, you can have rings containing P, N, and C atoms. These are often called phosphacycles.\n",
      "\n",
      "*   **Phosphorus-Containing Substituents:** Phosphorus-containing groups can be attached as substituents to an existing heterocyclic ring. Common examples include:\n",
      "    *   **Phosphine Groups (-PR2):** where R can be alkyl, aryl, or other groups.\n",
      "    *   **Phosphine Oxide Groups (-P(O)R2):**\n",
      "    *   **Phosphonate Groups (-PO(OR)2):**\n",
      "    *   **Phosphonium Salts ([PR4]+ X-):**\n",
      "\n",
      "*   **Bridged Structures:** Phosphorus can also be part of a bridge connecting two or more heterocyclic rings.\n",
      "\n",
      "**Types of Phosphorus Heterocycles:**\n",
      "\n",
      "*   **Phosphiranes:** Three-membered rings containing phosphorus.\n",
      "*   **Phosphetanes:** Four-membered rings containing phosphorus.\n",
      "*   **Phospholanes and Phospholes:** Five-membered rings containing phosphorus (saturated and unsaturated, respectively).\n",
      "*   **Phosphinanes:** Six-membered rings containing phosphorus.\n",
      "\n",
      "**Reactions for Incorporating Phosphorus:**\n",
      "\n",
      "The specific reaction used to incorporate phosphorus will depend on the starting materials and the desired product. Some common reactions include:\n",
      "\n",
      "*   **Reactions of Phosphorus Halides (e.g., PCl3, PCl5) with Ring Systems:** These can be used to introduce phosphorus directly into a ring or to attach phosphorus-containing substituents.\n",
      "*   **Wittig-type Reactions:** Phosphorus ylides can react with carbonyl compounds to form phosphorus-containing alkenes that can then be cyclized.\n",
      "*   **Cycloaddition Reactions:** Phosphorus-containing compounds can participate in cycloaddition reactions to form heterocyclic rings.\n",
      "\n",
      "**Applications of Phosphorus Heterocycles:**\n",
      "\n",
      "Phosphorus heterocycles have various applications in:\n",
      "\n",
      "*   **Catalysis:** Phosphorus ligands are widely used in homogeneous catalysis.\n",
      "*   **Coordination Chemistry:** They can act as ligands for metal complexes.\n",
      "*   **Materials Science:** They can be used in polymers and other materials.\n",
      "*   **Pharmaceutical Chemistry:** Some phosphorus heterocycles have biological activity.\n",
      "*   **Flame Retardants:** Phosphorus compounds are often used as flame retardants.\n",
      "\n",
      "**In summary, it is definitely possible to add phosphorus-related chemicals to heterocyclic rings, leading to a diverse range of phosphorus-containing heterocycles with various applications.** The specific method and resulting structure depend on the desired properties and the chosen reactants.\n"
     ]
    }
   ],
   "source": [
    "response3  = graph.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"Can we add phosporus related chemicals to this ring?\"}]\n",
    "    }, \n",
    "    config= thread\n",
    "    )\n",
    "    \n",
    "    # Print the final response1 \n",
    "print(response3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c285d",
   "metadata": {},
   "source": [
    "### How to Manage Thread IDs in Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06603f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In production, you need a strategy for generating & managing these IDs:\n",
    "\n",
    "Option A. Use User ID\n",
    "\n",
    "If each user logs in, use their user ID or email.\n",
    "\n",
    "Example: \"thread_id\": \"user_789\".\n",
    "\n",
    "Memory sticks with the user across sessions.\n",
    "\n",
    "Option B. Use Session ID\n",
    "\n",
    "If you want memory only during one session/tab, generate a random UUID at session start.\n",
    "\n",
    "Example: \"thread_id\": \"c2f9d5d2-6c81-4a0a-9a33\".\n",
    "\n",
    "When session ends, memory is discarded.\n",
    "\n",
    "Option C. Use Both\n",
    "\n",
    "Combine user ID + session ID.\n",
    "\n",
    "Example: \"thread_id\": \"user_789_session_001\".\n",
    "\n",
    "Lets you have multiple independent conversations per user.\n",
    "\n",
    "🛠️ 5. Where to Store Thread IDs?\n",
    "\n",
    "Frontend apps (React/Flutter/web) → store in cookies, localStorage, or sessionStorage.\n",
    "\n",
    "Backend APIs (FastAPI/Django) → pass thread_id in request headers or body.\n",
    "\n",
    "Databases → map thread_id → conversation logs, so you can reload later.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8915ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdb69524",
   "metadata": {},
   "source": [
    "### Human-in-the-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72cb914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "from datetime import datetime, timedelta\n",
    "import uuid, json, time, os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# LangGraph & LangChain imports\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages, AnyMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "#LLM and tools\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Small helper for date parsing\n",
    "from dateutil import parser as dateparser\n",
    "\n",
    "\n",
    "# Configure API keys\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
    "\n",
    "# Basic sanity checks \n",
    "if not GEMINI_API_KEY:\n",
    "    print(\"WARNING: GEMINI_API_KEY not set. Set GEMINI_API_KEY in environment or .env to use the LLM.\")\n",
    "if not TAVILY_API_KEY:\n",
    "    print(\"WARNING: TAVILY_API_KEY not set. Web search tool will fail without it.\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Agent State\n",
    "# ----------------------------\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    AgentState: conversation memory shape stored by the graph.\n",
    "\n",
    "    messages: list of messages (user/assistant/tool) - langgraph's add_messages decorator manages appending.\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# In-memory booking store (demo)\n",
    "# ----------------------------\n",
    "\n",
    "# For the demo we store tentative & confirmed bookings in a dict keyed by thread_id.\n",
    "# Production: persistent DB (Postgres/Redis) + transactional semantics.\n",
    "\n",
    "_bookings_store: Dict[str, List[Dict[str, Any]]] = {}\n",
    "\n",
    "# ----------------------------\n",
    "# Utility functions\n",
    "# ----------------------------\n",
    "def make_thread_id() -> str:\n",
    "    '''Create a new unique thread id (UUID4).'''\n",
    "    return str(uuid. uuid4())\n",
    "\n",
    "def parse_date_safe(date_str: str) -> datetime:\n",
    "    '''Try to parse a date string robustly using dateutil; raise ValueError on failure.'''\n",
    "    if not date_str or not isinstance(date_str, str):\n",
    "        raise ValueError(\"Invalid date input.\")\n",
    "    # Accept natural language like \"tomorrow\" or ISO dates\n",
    "    parsed = dateparser.parse(date_str, fuzzy=True)\n",
    "    if not parsed:\n",
    "        raise ValueError(f\"Could not parse date: {date_str}\")\n",
    "    return parsed\n",
    "\n",
    "def sanitize_location(loc: str) -> str:\n",
    "    \"\"\"Simple sanitization of location strings to avoid injection in mock tools.\"\"\"\n",
    "    return loc.strip()\n",
    "\n",
    "# ----------------------------\n",
    "# Tools Definitions\n",
    "# ----------------------------\n",
    "@tool\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Tool: web_search\n",
    "    - Uses TavilySearchResults to fetch top results for a query and returns a summarized string.\n",
    "\n",
    "    Returns:\n",
    "        A string with formatted search results (title, snippet, url) joined.\n",
    "    \"\"\"\n",
    "    # Defensive programming: fail gracefully if no API key\n",
    "    if not TAVILY_API_KEY:\n",
    "        return \"ERROR: TAVILY_API_KEY not configured.\"\n",
    "\n",
    "    try:\n",
    "        search = TavilySearchResults(api_key=TAVILY_API_KEY, max_results=5)\n",
    "        results = search.invoke(query)\n",
    "    except Exception as e:\n",
    "        return f\"ERROR: web_search failed: {e}\"\n",
    "\n",
    "    formatted = []\n",
    "    for r in results:\n",
    "        title = r.get(\"title\", \"No title\")\n",
    "        snippet = r.get(\"content\") or r.get(\"snippet\") or \"\"\n",
    "        url = r.get(\"url\", \"\")\n",
    "        formatted.append(f\"Title: {title}\\nSnippet: {snippet}\\nURL: {url}\")\n",
    "    return \"\\n\\n---\\n\\n\".join(formatted) if formatted else \"No results found.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def check_availability(origin: str, destination: str, depart_date: str) -> str:\n",
    "    \"\"\"\n",
    "    Tool: check_availability (mock)\n",
    "    - Checks whether seats are available on the requested route+date.\n",
    "    - For demo, availability logic is simplified.\n",
    "\n",
    "    Returns:\n",
    "        JSON string describing availability.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        depart_dt = parse_date_safe(depart_date)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Invalid date: {e}\"})\n",
    "\n",
    "    origin = sanitize_location(origin)\n",
    "    destination = sanitize_location(destination)\n",
    "\n",
    "    # Mock logic: if date is within next 365 days and origin != destination -> available\n",
    "    days_until = (depart_dt.date() - datetime.utcnow().date()).days\n",
    "    if origin.lower() == destination.lower():\n",
    "        return json.dumps({\"available\": False, \"reason\": \"Origin and destination are the same.\"})\n",
    "    if days_until < 0:\n",
    "        return json.dumps({\"available\": False, \"reason\": \"Date is in the past.\"})\n",
    "    if days_until > 365:\n",
    "        return json.dumps({\"available\": False, \"reason\": \"Date too far in future for demo provider.\"})\n",
    "    # Simulate limited capacity: if day-of-month is divisible by 13 -> low seats\n",
    "    low_capacity = (depart_dt.day % 13 == 0)\n",
    "    availability = {\"available\": True, \"low_capacity\": low_capacity, \"days_until\": days_until}\n",
    "    return json.dumps(availability)\n",
    "\n",
    "@tool\n",
    "def make_booking(thread_id: str, user_name: str, origin: str, destination: str, depart_date: str) -> str:\n",
    "    \"\"\"\n",
    "    Tool: make_booking (mock)\n",
    "    - Creates a tentative booking and stores it in the in-memory _bookings_store.\n",
    "    - Returns a JSON string with tentative booking details (including booking_id).\n",
    "    - Note: this is 'tentative' and requires human approval in this demo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        depart_dt = parse_date_safe(depart_date)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Invalid date: {e}\"})\n",
    "\n",
    "    origin = sanitize_location(origin)\n",
    "    destination = sanitize_location(destination)\n",
    "    booking_id = str(uuid.uuid4())\n",
    "\n",
    "    record = {\n",
    "        \"booking_id\": booking_id,\n",
    "        \"user_name\": user_name,\n",
    "        \"origin\": origin,\n",
    "        \"destination\": destination,\n",
    "        \"depart_date\": depart_dt.isoformat(),\n",
    "        \"status\": \"tentative\",\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "    }\n",
    "    _bookings_store.setdefault(thread_id, []).append(record)\n",
    "\n",
    "    # Return the tentative booking record\n",
    "    return json.dumps({\"result\": \"tentative_created\", \"booking\": record})\n",
    "\n",
    "\n",
    "@tool\n",
    "def confirm_booking(thread_id: str, booking_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Tool: confirm_booking (mock)\n",
    "    - Marks a tentative booking as 'confirmed'.\n",
    "    - Returns JSON with confirmation details or an error message.\n",
    "    \"\"\"\n",
    "    items = _bookings_store.get(thread_id, [])\n",
    "    for item in items:\n",
    "        if item[\"booking_id\"] == booking_id:\n",
    "            item[\"status\"] = \"confirmed\"\n",
    "            item[\"confirmed_at\"] = datetime.utcnow().isoformat()\n",
    "            return json.dumps({\"result\": \"confirmed\", \"booking\": item})\n",
    "    return json.dumps({\"error\": \"booking_id not found\"})\n",
    "\n",
    "\n",
    "@tool\n",
    "def cancel_booking(thread_id: str, booking_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Tool: cancel_booking (mock)\n",
    "    - Cancels a booking and records cancellation timestamp.\n",
    "    \"\"\"\n",
    "    items = _bookings_store.get(thread_id, [])\n",
    "    for item in items:\n",
    "        if item[\"booking_id\"] == booking_id:\n",
    "            item[\"status\"] = \"cancelled\"\n",
    "            item[\"cancelled_at\"] = datetime.utcnow().isoformat()\n",
    "            return json.dumps({\"result\": \"cancelled\", \"booking\": item})\n",
    "    return json.dumps({\"error\": \"booking_id not found\"})\n",
    "\n",
    "# Tool list used by LLM\n",
    "TOOLS = [web_search, check_availability, make_booking, confirm_booking, cancel_booking]\n",
    "\n",
    "# ToolNode to execute tools within the LangGraph\n",
    "tool_node = ToolNode(TOOLS)\n",
    "\n",
    "# ----------------------------\n",
    "# LLM Setup (Gemini)\n",
    "# ----------------------------\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\", api_key=GEMINI_API_KEY)\n",
    "\n",
    "# ----------------------------\n",
    "# Chatbot Node (decision maker)\n",
    "# ----------------------------\n",
    "def chatbot(state: AgentState):\n",
    "    \"\"\"\n",
    "    Chatbot node: binds the available tools to the LLM and asks the LLM to respond based on the conversation history.\n",
    "\n",
    "    Behavior:\n",
    "    - The LLM is given a system prompt that describes available tools and expected behavior.\n",
    "    - The chain returns a response. If the LLM decides to call a tool, the LLM's response will include a tool call in the structured format LangChain uses.\n",
    "    \"\"\"\n",
    "    system_text = (\n",
    "        \"You are a travel assistant. You may use tools for:\\n\"\n",
    "        \"- web_search(query)\\n\"\n",
    "        \"- check_availability(origin, destination, depart_date)\\n\"\n",
    "        \"- make_booking(thread_id, user_name, origin, destination, depart_date)\\n\"\n",
    "        \"- confirm_booking(thread_id, booking_id)\\n\"\n",
    "        \"- cancel_booking(thread_id, booking_id)\\n\\n\"\n",
    "        \"When you need up-to-date info, use web_search. When you want to create or confirm bookings, use the booking tools. \"\n",
    "        \"Always be conversational and verify user details before booking. If you create a booking, it will be tentative and will require human approval.\"\n",
    "    )\n",
    "\n",
    "    # The prompt includes the conversation history injected as {messages}.\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_text),\n",
    "        (\"placeholder\", \"{messages}\")\n",
    "    ])\n",
    "\n",
    "    # Bind tools to the LLM so it can generate tool call actions.\n",
    "    chain = prompt | llm.bind_tools(TOOLS)\n",
    "\n",
    "    # Invoke with full message history\n",
    "    response = chain.invoke({\"messages\": state[\"messages\"]})\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Router: decide next step after chatbot\n",
    "# ----------------------------\n",
    "def should_continue(state: AgentState):\n",
    "    \"\"\"\n",
    "    Determine where to route after chatbot:\n",
    "    - If LLM requested tool calls -> go to \"tools\" node\n",
    "    - If LLM asked for human approval -> go to \"human\" node\n",
    "    - Otherwise -> END\n",
    "    \"\"\"\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    # Chat message may have tool_calls attribute if LLM emitted a tool call action\n",
    "    if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    # Quick heuristic: if assistant asks for \"approval\" or contains \"please approve booking\" -> human review\n",
    "    # In production, use structured signals (e.g., message.metadata or special tokens)\n",
    "    txt = getattr(last_msg, \"content\", \"\")\n",
    "    if isinstance(txt, str) and (\"please approve\" in txt.lower() or \"awaiting approval\" in txt.lower()):\n",
    "        return \"human\"\n",
    "\n",
    "    return END\n",
    "\n",
    "# ----------------------------\n",
    "# Human-in-the-loop node\n",
    "# ----------------------------\n",
    "def human_approval_node(state: AgentState):\n",
    "    \"\"\"\n",
    "    Pause the graph and return the state for human review.\n",
    "    In this demo, we perform a CLI-based approval: print the last assistant message + tentative booking(s),\n",
    "    then ask the operator to approve / modify / reject.\n",
    "\n",
    "    In production:\n",
    "      - Persist paused state, notify a human via UI, email, or internal dashboard.\n",
    "      - Human edits state and resumes the graph via API.\n",
    "    \"\"\"\n",
    "    # Extract context for display\n",
    "    messages = state[\"messages\"]\n",
    "    last_assistant = messages[-1] if messages else None\n",
    "\n",
    "    # Show tentative bookings for this thread (if any)\n",
    "    print(\"\\n=== HUMAN REVIEW REQUIRED ===\")\n",
    "    print(\"Assistant message (awaiting approval):\")\n",
    "    print(getattr(last_assistant, \"content\", str(last_assistant)))\n",
    "    print(\"\\nTentative bookings in store for this thread:\")\n",
    "    # Last message may contain thread id - we expect thread_id in the config of invocation\n",
    "    # Here we just show all entries; in production, map via thread id\n",
    "    for tid, recs in _bookings_store.items():\n",
    "        for r in recs:\n",
    "            if r[\"status\"] == \"tentative\":\n",
    "                print(json.dumps(r, indent=2))\n",
    "    print(\"=============================\\n\")\n",
    "\n",
    "    # CLI prompt: approve or reject\n",
    "    while True:\n",
    "        resp = input(\"Human action (approve <booking_id> / reject <booking_id> / skip): \").strip()\n",
    "        if resp.lower() == \"skip\":\n",
    "            print(\"Skipping human approval (agent will continue but booking stays tentative).\")\n",
    "            return state\n",
    "        parts = resp.split()\n",
    "        if len(parts) == 2 and parts[0].lower() in {\"approve\", \"reject\"}:\n",
    "            action, booking_id = parts[0].lower(), parts[1]\n",
    "            if action == \"approve\":\n",
    "                print(f\"Approving booking {booking_id} ...\")\n",
    "                confirm_booking(\"\", booking_id)  # thread_id not used in mock confirm; in prod supply correct thread\n",
    "                print(\"Booking approved.\")\n",
    "            else:\n",
    "                print(f\"Cancelling booking {booking_id} ...\")\n",
    "                cancel_booking(\"\", booking_id)\n",
    "                print(\"Booking cancelled.\")\n",
    "            return state\n",
    "        print(\"Invalid input. Example commands: 'approve <booking_id>', 'reject <booking_id>', or 'skip'.\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Graph building & memory\n",
    "# ----------------------------\n",
    "graph_builder = StateGraph(AgentState)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_node(\"human\", human_approval_node)\n",
    "\n",
    "# Start -> chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Conditional routing after chatbot\n",
    "graph_builder.add_conditional_edges(\"chatbot\", should_continue, {\"tools\": \"tools\", \"human\": \"human\", END: END})\n",
    "\n",
    "# After tools, go back to chatbot for further reasoning\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# After human review, go back to chatbot\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "\n",
    "# Memory: small MemorySaver checkpointing; replace with SQLite/Postgres savers in production\n",
    "memory = InMemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Helper: invoke with thread_id management\n",
    "# ----------------------------\n",
    "def invoke_with_thread(messages: List[Dict[str, str]], thread_id: str = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Helper to invoke the compiled graph with message history and thread_id.\n",
    "    If thread_id is None, a new one is generated (stateless chat).\n",
    "    \"\"\"\n",
    "    if thread_id is None:\n",
    "        thread_id = make_thread_id()\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    # Graph.invoke expects the initial partial state; we provide messages and config\n",
    "    result = graph.invoke({\"messages\": messages}, config=config)\n",
    "    return {\"thread_id\": thread_id, \"result\": result}\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# CLI demo\n",
    "# ----------------------------\n",
    "def cli_demo():\n",
    "    print(\"Travel Booking Agent - Demo\")\n",
    "    print(\"Start a new conversation or resume an existing thread.\")\n",
    "    thread_id = None\n",
    "    while True:\n",
    "        if not thread_id:\n",
    "            choice = input(\"\\nCommands:\\n [n] new conversation\\n [r] resume with thread_id\\n [q] quit\\nChoose: \").strip().lower()\n",
    "            if choice == \"n\":\n",
    "                thread_id = None\n",
    "            elif choice == \"r\":\n",
    "                tid = input(\"Enter thread_id to resume: \").strip()\n",
    "                if tid:\n",
    "                    thread_id = tid\n",
    "                else:\n",
    "                    print(\"Invalid thread_id.\")\n",
    "                    continue\n",
    "            elif choice == \"q\":\n",
    "                print(\"Exiting.\")\n",
    "                return\n",
    "            else:\n",
    "                print(\"Unknown command.\")\n",
    "                continue\n",
    "\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "            print(\"Ending session.\")\n",
    "            return\n",
    "\n",
    "        # Prepare message payload and call graph\n",
    "        messages = [{\"role\": \"user\", \"content\": user_input}]\n",
    "        out = invoke_with_thread(messages, thread_id)\n",
    "        thread_id = out[\"thread_id\"]\n",
    "        result_state = out[\"result\"]\n",
    "\n",
    "        # Print the assistant's last message\n",
    "        final_msg = result_state[\"messages\"][-1]\n",
    "        print(\"\\nAssistant:\", getattr(final_msg, \"content\", final_msg))\n",
    "\n",
    "        print(f\"[Thread ID: {thread_id}] (save this if you want to resume the conversation later)\")\n",
    "\n",
    "# Run CLI if executed\n",
    "# if __name__ == \"__main__\":\n",
    "#     cli_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0ee2504",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Increase retries / delay (suggested by the error message)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Image(graph.get_graph().draw_mermaid_png())\u001b[39;00m\n",
      "File \u001b[1;32md:\\Langgraph\\.venv\\lib\\site-packages\\langchain_core\\runnables\\graph.py:693\u001b[0m, in \u001b[0;36mGraph.draw_mermaid_png\u001b[1;34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m draw_mermaid_png\n\u001b[0;32m    687\u001b[0m mermaid_syntax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw_mermaid(\n\u001b[0;32m    688\u001b[0m     curve_style\u001b[38;5;241m=\u001b[39mcurve_style,\n\u001b[0;32m    689\u001b[0m     node_colors\u001b[38;5;241m=\u001b[39mnode_colors,\n\u001b[0;32m    690\u001b[0m     wrap_label_n_words\u001b[38;5;241m=\u001b[39mwrap_label_n_words,\n\u001b[0;32m    691\u001b[0m     frontmatter_config\u001b[38;5;241m=\u001b[39mfrontmatter_config,\n\u001b[0;32m    692\u001b[0m )\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Langgraph\\.venv\\lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:293\u001b[0m, in \u001b[0;36mdraw_mermaid_png\u001b[1;34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[0m\n\u001b[0;32m    287\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m    288\u001b[0m         _render_mermaid_using_pyppeteer(\n\u001b[0;32m    289\u001b[0m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[0;32m    290\u001b[0m         )\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m draw_method \u001b[38;5;241m==\u001b[39m MermaidDrawMethod\u001b[38;5;241m.\u001b[39mAPI:\n\u001b[1;32m--> 293\u001b[0m     img_bytes \u001b[38;5;241m=\u001b[39m \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     supported_methods \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([m\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "File \u001b[1;32md:\\Langgraph\\.venv\\lib\\site-packages\\langchain_core\\runnables\\graph_mermaid.py:450\u001b[0m, in \u001b[0;36m_render_mermaid_using_api\u001b[1;34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m     ) \u001b[38;5;241m+\u001b[39m error_msg_suffix\n\u001b[1;32m--> 450\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mRequestException, requests\u001b[38;5;241m.\u001b[39mTimeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m max_retries:\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 502.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "# Increase retries / delay (suggested by the error message)\n",
    "Image(graph.get_graph().draw_mermaid_png(max_retries=5, retry_delay=2.0))\n",
    "\n",
    "# Image(graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a4fa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90bcc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "import asyncio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
